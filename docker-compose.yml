version: '3.8'

services:
  test:
    build:
      context: .
      dockerfile: Dockerfile
    image: lora-finetuning-test:latest
    container_name: lora-test

    # Enable GPU support (requires nvidia-docker)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # Mount volumes for cache and outputs
    volumes:
      - ./cache:/app/.cache
      - ./test_lora_output:/app/test_lora_output

    # Environment variables
    environment:
      - PYTHONUNBUFFERED=1
      - HF_HOME=/app/.cache/huggingface
      - TRANSFORMERS_CACHE=/app/.cache/huggingface/transformers
      - CUDA_VISIBLE_DEVICES=0

    # Run the test
    command: python test_finetuning.py
