{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdJrmJ9z95cH"
      },
      "source": [
        "# LoRA Fine-Tuning with SmolLM2-360M\n",
        "\n",
        "**Base Model:** HuggingFaceTB/SmolLM2-360M-Instruct  \n",
        "**Dataset:** shawhin/imdb-truncated (1000 train, 1000 validation samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X0GwuzK95cJ"
      },
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "m-X9mOLT95cJ"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers datasets peft accelerate bitsandbytes trl torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "CbbNutse95cJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import json\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnODGhbW95cJ"
      },
      "source": [
        "## 2. Load Dataset and Inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAyL5y5f95cK",
        "outputId": "3eab62d3-d3c9-45ee-9e8b-1b18a18b4ee0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['label', 'text'],\n",
            "        num_rows: 1000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['label', 'text'],\n",
            "        num_rows: 1000\n",
            "    })\n",
            "})\n",
            "\n",
            "Sample from training set:\n",
            "{'label': 1, 'text': '. . . or type on a computer keyboard, they\\'d probably give this eponymous film a rating of \"10.\" After all, no elephants are shown being killed during the movie; it is not even implied that any are hurt. To the contrary, the master of ELEPHANT WALK, John Wiley (Peter Finch), complains that he cannot shoot any of the pachyderms--no matter how menacing--without a permit from the government (and his tone suggests such permits are not within the realm of probability). Furthermore, the elements conspire--in the form of an unusual drought and a human cholera epidemic--to leave the Wiley plantation house vulnerable to total destruction by the Elephant People (as the natives dub them) to close the story. If you happen to see the current release EARTH, you\\'ll detect the Elephant People are faring less well today.'}\n"
          ]
        }
      ],
      "source": [
        "# Load the IMDB dataset\n",
        "dataset = load_dataset('shawhin/imdb-truncated')\n",
        "print(dataset)\n",
        "print(\"\\nSample from training set:\")\n",
        "print(dataset['train'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7XCj87K95cK"
      },
      "source": [
        "## 3. Load Base Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJwTprQm95cK",
        "outputId": "66f9fb5f-e3f5-4c63-c87a-f0ed6a579aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: HuggingFaceTB/SmolLM2-360M-Instruct\n",
            "Model parameters: 361,821,120\n"
          ]
        }
      ],
      "source": [
        "# Model configuration\n",
        "model_name = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Set padding token if not present\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Load base model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(f\"Model loaded: {model_name}\")\n",
        "print(f\"Model parameters: {base_model.num_parameters():,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aQBHnRV95cK"
      },
      "source": [
        "## 4. Test Base Model (Before Fine-Tuning)\n",
        "\n",
        "Let's evaluate the base model on a subset of the validation dataset to establish a baseline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q09tbD6Z95cK",
        "outputId": "686f7b59-da8f-4fa9-8e1d-c7abfc56fddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "BASE MODEL EVALUATION (Before Fine-Tuning)\n",
            "================================================================================\n",
            "\n",
            "Evaluating on 100 validation samples...\n",
            "\n",
            "Example 1:\n",
            "  Review: Disgused as an Asian Horror, \"A Tale Of Two Sisters\" is actually a complex character driven psycholo...\n",
            "  True sentiment: positive\n",
            "  Raw output: positive\n",
            "\n",
            "What is the sentiment of the review\n",
            "  Predicted: positive\n",
            "  Correct: ✓\n",
            "\n",
            "Example 2:\n",
            "  Review: I am from Texas and my family vacationed a couple of years ago to Sante Fe with my brother. He sugge...\n",
            "  True sentiment: positive\n",
            "  Raw output: positive\n",
            "\n",
            "Now classify this one:\n",
            "Review\n",
            "  Predicted: positive\n",
            "  Correct: ✓\n",
            "\n",
            "Example 3:\n",
            "  Review: Robert Altman's \"Quintet\" is a dreary, gloomy, hard to follow thriller where you finally give up aft...\n",
            "  True sentiment: negative\n",
            "  Raw output: negative\n",
            "\n",
            "Now classify this one:\n",
            "Review\n",
            "  Predicted: negative\n",
            "  Correct: ✓\n",
            "\n",
            "Example 4:\n",
            "  Review: ** HERE BE SPOILERS ** <br /><br />Recap: Macleane (Miller) witnesses a robbery by Plunkett (Carlyle...\n",
            "  True sentiment: positive\n",
            "  Raw output: positive\n",
            "\n",
            "What is the sentiment of the review\n",
            "  Predicted: positive\n",
            "  Correct: ✓\n",
            "\n",
            "Example 5:\n",
            "  Review: I first saw this movie in the theater. I was 10. I just watched it a second time and I must say it w...\n",
            "  True sentiment: positive\n",
            "  Raw output: positive\n",
            "  Predicted: positive\n",
            "  Correct: ✓\n",
            "\n",
            "Progress: 20/100 samples processed...\n",
            "Progress: 40/100 samples processed...\n",
            "Progress: 60/100 samples processed...\n",
            "Progress: 80/100 samples processed...\n",
            "Progress: 100/100 samples processed...\n",
            "\n",
            "================================================================================\n",
            "BASE MODEL RESULTS:\n",
            "Accuracy: 66.00% (66/100 correct)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "def generate_response(model, prompt, max_new_tokens=20):\n",
        "    \"\"\"Generate response from model\"\"\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=0.1,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "def evaluate_model(model, dataset, num_samples=100, debug=False):\n",
        "    \"\"\"Evaluate model accuracy on sentiment classification\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    samples_to_test = min(num_samples, len(dataset['validation']))\n",
        "\n",
        "    print(f\"Evaluating on {samples_to_test} validation samples...\\n\")\n",
        "\n",
        "    for i in range(samples_to_test):\n",
        "        sample = dataset['validation'][i]\n",
        "        review_text = sample['text']\n",
        "        true_label = sample['label']\n",
        "        true_sentiment = \"positive\" if true_label == 1 else \"negative\"\n",
        "\n",
        "        prompt = \"\"\"You are a sentiment classifier.\n",
        "Read each review and respond only with 'positive' or 'negative'.\n",
        "\n",
        "Example 1:\n",
        "Review: This movie was boring and too long.\n",
        "Answer: negative\n",
        "\n",
        "Example 2:\n",
        "Review: I loved the characters and story.\n",
        "Answer: positive\n",
        "\n",
        "Now classify this one:\n",
        "Review: \"\"\" + review_text + \"\\nAnswer:\"\n",
        "\n",
        "        # Generate prediction\n",
        "        output = generate_response(model, prompt, max_new_tokens=10)\n",
        "\n",
        "        # Extract only the generated part (after the prompt)\n",
        "        generated_text = output[len(prompt):].strip()\n",
        "\n",
        "        # Extract predicted sentiment\n",
        "        generated_lower = generated_text.lower()\n",
        "        if \"positive\" in generated_lower and \"negative\" not in generated_lower:\n",
        "            predicted_sentiment = \"positive\"\n",
        "        elif \"negative\" in generated_lower and \"positive\" not in generated_lower:\n",
        "            predicted_sentiment = \"negative\"\n",
        "        else:\n",
        "            predicted_sentiment = None\n",
        "\n",
        "        if predicted_sentiment == true_sentiment:\n",
        "            correct += 1\n",
        "\n",
        "        # Show first 5 examples with debug info\n",
        "        if i < 5:\n",
        "            print(f\"Example {i+1}:\")\n",
        "            print(f\"  Review: {review_text[:100]}...\")\n",
        "            print(f\"  True sentiment: {true_sentiment}\")\n",
        "            if debug:\n",
        "                print(f\"  Raw output: {generated_text}\")\n",
        "            print(f\"  Predicted: {predicted_sentiment}\")\n",
        "            print(f\"  Correct: {'✓' if predicted_sentiment == true_sentiment else '✗'}\")\n",
        "            print()\n",
        "\n",
        "        total += 1\n",
        "\n",
        "        if (i + 1) % 20 == 0:\n",
        "            print(f\"Progress: {i+1}/{samples_to_test} samples processed...\")\n",
        "\n",
        "    accuracy = correct / total if total > 0 else 0\n",
        "    return accuracy, correct, total\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"BASE MODEL EVALUATION (Before Fine-Tuning)\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "\n",
        "base_acc, base_correct, base_total = evaluate_model(base_model, dataset, num_samples=100, debug=True)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"BASE MODEL RESULTS:\")\n",
        "print(f\"Accuracy: {base_acc:.2%} ({base_correct}/{base_total} correct)\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYe71eyY95cL"
      },
      "source": [
        "## 5. Prepare Dataset for Fine-Tuning\n",
        "\n",
        "Format the IMDB dataset for sentiment analysis training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "2cb875ff236443c0955e9c4c77284b32",
            "4d0403f684c64f1db94c9a73eb1ebeb8",
            "f048e205ad3249e3bbac9b14f72fbd8e",
            "d75f010b18f744068536310e098ea6bd",
            "00f1e114ec8a447cb1ae32d85777b328",
            "1762e8e61c25471a990330c4f841e124",
            "a47090c36e0440f4ac0df76af5216883",
            "55cf7e3f95fe47c5911c9837f482fabc",
            "807370196e94498a94324d91ce433290",
            "1b1f3c127eb946f695d16c62ad76cc19",
            "4007add5b49f4bc0a40cd002a6aed14c",
            "64a4e6807ff24b28a0f416a5c2905743",
            "47b946f1808a47a485dbd4255ce13205",
            "f44c3e21ded74a9f8e22bb25e22fcb99",
            "da900444c8d74e529d8e1c46221a46f9",
            "8544b5cb52aa47429a5e9a90295701ff",
            "de261f73ac6f4468acae00545c78190e",
            "e0b90e29d8e54249aadb6d79aed77787",
            "02bd96380bd842f398c64a6c3302827e",
            "cb9cbec5e4a848f9a112ad2a8a9f2ec6",
            "5398a44f0ab54fb49003d9eb3896a512",
            "9729d4c70e91439b8fb8d41e80d1021d"
          ]
        },
        "id": "-MF7F-aU95cL",
        "outputId": "3be85416-372c-4dd1-c843-69612c9dad31"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cb875ff236443c0955e9c4c77284b32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64a4e6807ff24b28a0f416a5c2905743"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample formatted training example:\n",
            "You are a sentiment classifier. \n",
            "Read each review and respond only with 'positive' or 'negative'.\n",
            "\n",
            "Example 1:\n",
            "Review: This movie was boring and too long.\n",
            "Answer: negative\n",
            "\n",
            "Example 2:\n",
            "Review: I loved the characters and story.\n",
            "Answer: positive\n",
            "\n",
            "Now classify this one:\n",
            "Review: . . . or type on a computer keyboard, they'd probably give this eponymous film a rating of \"10.\" After all, no elephants are s...\n"
          ]
        }
      ],
      "source": [
        "def create_prompt(example):\n",
        "    \"\"\"Create instruction-formatted prompt for sentiment analysis\"\"\"\n",
        "    sentiment = \"positive\" if example['label'] == 1 else \"negative\"\n",
        "\n",
        "    # Instruction format\n",
        "    prompt = \"\"\"You are a sentiment classifier.\n",
        "Read each review and respond only with 'positive' or 'negative'.\n",
        "\n",
        "Example 1:\n",
        "Review: This movie was boring and too long.\n",
        "Answer: negative\n",
        "\n",
        "Example 2:\n",
        "Review: I loved the characters and story.\n",
        "Answer: positive\n",
        "\n",
        "Now classify this one:\n",
        "Review: \"\"\" + example['text'] + \"\\nAnswer:\"\n",
        "\n",
        "    return {\"text\": prompt}\n",
        "\n",
        "# Format datasets\n",
        "formatted_train = dataset['train'].map(create_prompt, remove_columns=['label'])\n",
        "formatted_val = dataset['validation'].map(create_prompt, remove_columns=['label'])\n",
        "\n",
        "print(\"Sample formatted training example:\")\n",
        "print(formatted_train[0]['text'][:400] + \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "7ce94c464ec64240a57a4f77c92e5baf",
            "11e8ef7f32f849929c25b6fcc03d8ee6",
            "4307087a1f4947b7a225f84d3ffa2a15",
            "d71cd640b2664f2b93e4247bb50750e2",
            "1ae92b61cc794c97a13d85c0dd139f83",
            "9d12de5deab34050a19d5d1e12bd7c61",
            "e7627cf098714baba663b25a9e950d3f",
            "e09b392e56064f76a26df90daacb2abe",
            "df7a2253bd8d4caf8847bdf37db7c107",
            "1717eb33b028496b8f3b87d0d5d93c96",
            "77baea33a5de445a8fafce354073cf77",
            "1d56a59035a74653a05b629c3d3ba558",
            "e25bafca87b341a3b3f4ff5b1f9e4566",
            "478f125165e14640a1a10400f62ae729",
            "7a13aae50c364fdc86ca08a46cc061a0",
            "66c3e1cb6ab0415583cdf482036e3728",
            "d413b4b13ccf4064804825662e36598b",
            "14ff40d6e0504b0bbbdcea72270949e7",
            "c1137f146fd4443e9c66d35a65f12e01",
            "ee7353a22230423abfeb6851413a92c9",
            "6ad5a1ef250341c68d14e668eefa098e",
            "d848b925b9434d21b1c5b2128bd979dc"
          ]
        },
        "id": "BtgMHCRq95cL",
        "outputId": "22f35863-c11e-4608-883f-4c5a2e0721f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ce94c464ec64240a57a4f77c92e5baf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d56a59035a74653a05b629c3d3ba558"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenized training samples: 1000\n",
            "Tokenized validation samples: 1000\n"
          ]
        }
      ],
      "source": [
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize the text data\"\"\"\n",
        "    tokenized = tokenizer(\n",
        "        examples['text'],\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=None\n",
        "    )\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "# Tokenize datasets\n",
        "tokenized_train = formatted_train.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=['text']\n",
        ")\n",
        "\n",
        "tokenized_val = formatted_val.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=['text']\n",
        ")\n",
        "\n",
        "print(f\"\\nTokenized training samples: {len(tokenized_train)}\")\n",
        "print(f\"Tokenized validation samples: {len(tokenized_val)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM5F4OqY95cL"
      },
      "source": [
        "## 6. Configure LoRA and PEFT\n",
        "\n",
        "Set up Low-Rank Adaptation (LoRA) configuration for efficient fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh_33UlQ95cL",
        "outputId": "7b9d50b6-063d-4bd2-da9e-3d09c800c0c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA Configuration:\n",
            "LoraConfig(task_type=<TaskType.CAUSAL_LM: 'CAUSAL_LM'>, peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=16, target_modules={'v_proj', 'q_proj', 'o_proj', 'k_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, target_parameters=None)\n"
          ]
        }
      ],
      "source": [
        "# LoRA configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,                          # Rank of the low-rank matrices\n",
        "    lora_alpha=32,                 # Scaling factor\n",
        "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],  # Modules to apply LoRA\n",
        "    lora_dropout=0.05,             # Dropout probability\n",
        "    bias=\"none\",                   # Bias training strategy\n",
        "    task_type=TaskType.CAUSAL_LM   # Task type\n",
        ")\n",
        "\n",
        "print(\"LoRA Configuration:\")\n",
        "print(lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd2qYgD-95cL",
        "outputId": "b9ffd673-0a31-4ce3-d953-9951ed66446b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,276,800 || all params: 365,097,920 || trainable%: 0.8975\n"
          ]
        }
      ],
      "source": [
        "# Create a fresh model for training\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Enable gradient checkpointing for memory efficiency\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# Prepare model for training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# Apply LoRA\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Print trainable parameters\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bT-VnKyG95cL"
      },
      "source": [
        "## 7. Configure Training Arguments and Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eO6nUL-95cL",
        "outputId": "002fc5e9-592e-4fe3-c145-fbb3739d9d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainer initialized successfully!\n"
          ]
        }
      ],
      "source": [
        "# Output directory for checkpoints\n",
        "output_dir = \"./lora_finetuned_smollm2\"\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    warmup_steps=100,\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oXiBxmh95cL"
      },
      "source": [
        "## 8. Train the Model\n",
        "\n",
        "This will take several minutes depending on your hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "-88zP5TA95cL",
        "outputId": "32841375-675d-417d-df60-d5573425fa97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Start time: 2025-11-11 13:05:59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [189/189 05:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.844700</td>\n",
              "      <td>2.335153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.314100</td>\n",
              "      <td>2.227597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.219300</td>\n",
              "      <td>2.222339</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training completed!\n",
            "End time: 2025-11-11 13:12:01\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting training...\")\n",
        "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "print(f\"\\nTraining completed!\")\n",
        "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ1nRPfP95cL"
      },
      "source": [
        "## 9. Test Fine-Tuned Model and Compare\n",
        "\n",
        "Load the fine-tuned model and compare its performance with the base model on the same validation samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmk7xlmU95cL",
        "outputId": "3d476baa-8994-4fb3-8fa1-4afb9ef7851e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "# Load base model again (fresh)\n",
        "base_model_test = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Load fine-tuned model (base + LoRA adapter)\n",
        "finetuned_model = PeftModel.from_pretrained(\n",
        "    base_model_test,\n",
        "    lora_adapter_path\n",
        ")\n",
        "\n",
        "print(\"Fine-tuned model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxoXKt_z95cL",
        "outputId": "da047251-eb6a-47cc-89e0-57298ce30c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FINE-TUNED MODEL EVALUATION\n",
            "================================================================================\n",
            "\n",
            "Evaluating on 100 validation samples...\n",
            "\n",
            "Example 1:\n",
            "  Review: Disgused as an Asian Horror, \"A Tale Of Two Sisters\" is actually a complex character driven psycholo...\n",
            "  True sentiment: positive\n",
            "  Predicted: positive\n",
            "  Correct: ✓\n",
            "\n",
            "Example 2:\n",
            "  Review: I am from Texas and my family vacationed a couple of years ago to Sante Fe with my brother. He sugge...\n",
            "  True sentiment: positive\n",
            "  Predicted: positive\n",
            "  Correct: ✓\n",
            "\n",
            "Example 3:\n",
            "  Review: Robert Altman's \"Quintet\" is a dreary, gloomy, hard to follow thriller where you finally give up aft...\n",
            "  True sentiment: negative\n",
            "  Predicted: negative\n",
            "  Correct: ✓\n",
            "\n",
            "Example 4:\n",
            "  Review: ** HERE BE SPOILERS ** <br /><br />Recap: Macleane (Miller) witnesses a robbery by Plunkett (Carlyle...\n",
            "  True sentiment: positive\n",
            "  Predicted: positive\n",
            "  Correct: ✓\n",
            "\n",
            "Example 5:\n",
            "  Review: I first saw this movie in the theater. I was 10. I just watched it a second time and I must say it w...\n",
            "  True sentiment: positive\n",
            "  Predicted: positive\n",
            "  Correct: ✓\n",
            "\n",
            "Progress: 20/100 samples processed...\n",
            "Progress: 40/100 samples processed...\n",
            "Progress: 60/100 samples processed...\n",
            "Progress: 80/100 samples processed...\n",
            "Progress: 100/100 samples processed...\n",
            "\n",
            "================================================================================\n",
            "FINE-TUNED MODEL RESULTS:\n",
            "Accuracy: 82.00% (82/100 correct)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"FINE-TUNED MODEL EVALUATION\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "\n",
        "ft_acc, ft_correct, ft_total = evaluate_model(finetuned_model, dataset, num_samples=100)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"FINE-TUNED MODEL RESULTS:\")\n",
        "print(f\"Accuracy: {ft_acc:.2%} ({ft_correct}/{ft_total} correct)\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yzuqGQ995cL"
      },
      "source": [
        "## 10. Compare Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6WYVG1r95cL",
        "outputId": "39dd6893-d830-454d-ebb9-2940a2ddb0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "MODEL COMPARISON: Base vs Fine-Tuned\n",
            "================================================================================\n",
            "\n",
            "Base Model Accuracy:       66.00% (66/100)\n",
            "Fine-Tuned Model Accuracy: 82.00% (82/100)\n",
            "\n",
            "Absolute Improvement:      16.00%\n",
            "Relative Improvement:      24.2%\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MODEL COMPARISON: Base vs Fine-Tuned\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nBase Model Accuracy:       {base_acc:.2%} ({base_correct}/{base_total})\")\n",
        "print(f\"Fine-Tuned Model Accuracy: {ft_acc:.2%} ({ft_correct}/{ft_total})\")\n",
        "print(f\"\\nAbsolute Improvement:      {(ft_acc - base_acc):.2%}\")\n",
        "print(f\"Relative Improvement:      {((ft_acc - base_acc) / base_acc * 100):.1f}%\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVc6OpUq95cM"
      },
      "source": [
        "## 12. Summary and Next Steps\n",
        "\n",
        "### What we accomplished:\n",
        "1. ✅ Evaluated the base SmolLM2-360M model on validation data\n",
        "2. ✅ Fine-tuned using LoRA/PEFT on 1000 IMDB training reviews\n",
        "3. ✅ Evaluated fine-tuned model on the same validation samples\n",
        "4. ✅ Compared base vs fine-tuned model performance quantitatively\n",
        "5. ✅ Saved the LoRA adapter for future use\n",
        "\n",
        "### Key Takeaways:\n",
        "- LoRA allows efficient fine-tuning with minimal trainable parameters\n",
        "- The fine-tuned model shows measurable improvement on sentiment classification\n",
        "- Used proper train/validation split to ensure unbiased evaluation\n",
        "- Validation data was never seen during training\n",
        "\n",
        "### To use the fine-tuned model later:\n",
        "```python\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"HuggingFaceTB/SmolLM2-360M-Instruct\")\n",
        "model = PeftModel.from_pretrained(base_model, \"./lora_adapter_smollm2_sentiment\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./lora_adapter_smollm2_sentiment\")\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
